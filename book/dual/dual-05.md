---
id: urn:swd:toc:v2:dual:05
title: "Dual 05 — Explainability UI"
cluster: dual
type: WebPage
status: draft
keywords:
  - explainability
  - transparency
  - trust
  - reasoning
related:
  - urn:swd:toc:v2:dual:04
  - urn:swd:toc:v2:dual:06
  - urn:swd:toc:v2:semantics:05
  - urn:swd:toc:v2:semantics:04
  - urn:swd:toc:v2:ops:04
---

# Dual 05 — Explainability UI

If a system cannot explain itself, it cannot be trusted.

Explainability is not an AI feature.  
It is a **design obligation**.

## What explainability really means

Explainability answers:

- what happened
- why it happened
- who or what caused it
- under which rules
- with which confidence

This applies equally to human actions and agent actions.

## Explainability is not debugging

Debugging is for builders.  
Explainability is for operators.

Designers must surface explanations that are:

- contextual
- proportional to risk
- traceable to rules
- consistent across surfaces

## Explainability for humans

Human-facing explainability may include:

- timelines of actions
- rationale summaries
- links to governing rules
- visibility into uncertainty

The goal is understanding, not justification.

## Explainability for agents

Agent-facing explainability requires:

- machine-readable rationale
- explicit rule references
- confidence scores
- provenance links

If an agent cannot explain itself, it should be stopped.

## Continue exploring

- → [Dual 06 — Audit Surfaces](urn:swd:toc:v2:dual:06)
- → [Semantics 05 — Provenance and Trust](urn:swd:toc:v2:semantics:05)
- → [Ops 04 — Observability](urn:swd:toc:v2:ops:04)
- → [Dual 04](urn:swd:toc:v2:dual:04)
